{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d62ee3f1-a3ae-4805-bd65-b7c7b87299c2",
   "metadata": {},
   "source": [
    "### Info on data from Kaggle and UNIC\n",
    "+ Compeititon's goal was to predict item sales at stores in various locations for two 28-day time periods.\n",
    "+ Data is focused on series that display intermittency, i.e., sporadic demand including zeros.\n",
    "+ Based on hierarchical sales data, generously made available by Walmart, starting at the item level and aggregating to that of departments, product categories and stores in three geographical areas of the US: California, Texas, and Wisconsin.\n",
    "+ Besides the time series data, it also included explanatory variables such as price, promotions, day of the week, and special events (e.g. Super Bowl, Valentine’s Day, and Orthodox Easter) that affect sales which are used to improve forecasting accuracy.\n",
    "+ calendar.csv - Contains information about the dates on which the products are sold.\n",
    "+ sales_train_validation.csv - Contains the historical daily unit sales data per product and store [d_1 - d_1913]\n",
    "+ sell_prices.csv - Contains information about the price of the products sold per store and date.\n",
    "+ sales_train_evaluation.csv - Includes sales [d_1 - d_1941]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8655ea2-0c57-4416-996c-a2424ef9fb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e36f2b6-4f98-4c5c-bb1b-65c19c775c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# where the files are strored\n",
    "DATA_RAW = '../data/raw/m5-forecasting-accuracy/'\n",
    "DATA_PROCESSED = '../data/processed/'\n",
    "\n",
    "sales_file = os.path.join(DATA_RAW, \"sales_train_validation.csv\")\n",
    "calendar_file = os.path.join(DATA_RAW, \"calendar.csv\")\n",
    "prices_file = os.path.join(DATA_RAW, \"sell_prices.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcf29ee7-4c84-4171-abc3-0dbd81f53493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load smaller support data\n",
    "calendar = pd.read_csv(calendar_file)\n",
    "\n",
    "# below helps with merging calendar in cells below\n",
    "calendar['d'] = calendar['d'].astype(str)\n",
    "\n",
    "prices = pd.read_csv(prices_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74e3a1b6-2e9d-4db5-8545-502cc7783043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to process data in chunks. Getting memory issues\n",
    "chunk_size = 1000 # num of rows to process\n",
    "output_chunks = []\n",
    "\n",
    "reader = pd.read_csv(sales_file, chunksize=chunk_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce8085f6-b86e-4949-a918-002136fe24ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 1\n",
      "Chunk 1 processed. Shape: (1576972, 22)\n",
      "Processing chunk 2\n",
      "Chunk 2 processed. Shape: (1529918, 22)\n",
      "Processing chunk 3\n",
      "Chunk 3 processed. Shape: (1507084, 22)\n",
      "Processing chunk 4\n",
      "Chunk 4 processed. Shape: (1463250, 22)\n",
      "Processing chunk 5\n",
      "Chunk 5 processed. Shape: (1235036, 22)\n",
      "Processing chunk 6\n",
      "Chunk 6 processed. Shape: (1495548, 22)\n",
      "Processing chunk 7\n",
      "Chunk 7 processed. Shape: (1571918, 22)\n",
      "Processing chunk 8\n",
      "Chunk 8 processed. Shape: (1527979, 22)\n",
      "Processing chunk 9\n",
      "Chunk 9 processed. Shape: (1457251, 22)\n",
      "Processing chunk 10\n",
      "Chunk 10 processed. Shape: (1535588, 22)\n",
      "Processing chunk 11\n",
      "Chunk 11 processed. Shape: (1500091, 22)\n",
      "Processing chunk 12\n",
      "Chunk 12 processed. Shape: (1525193, 22)\n",
      "Processing chunk 13\n",
      "Chunk 13 processed. Shape: (1567676, 22)\n",
      "Processing chunk 14\n",
      "Chunk 14 processed. Shape: (1545157, 22)\n",
      "Processing chunk 15\n",
      "Chunk 15 processed. Shape: (1536365, 22)\n",
      "Processing chunk 16\n",
      "Chunk 16 processed. Shape: (1561145, 22)\n",
      "Processing chunk 17\n",
      "Chunk 17 processed. Shape: (1549910, 22)\n",
      "Processing chunk 18\n",
      "Chunk 18 processed. Shape: (1530520, 22)\n",
      "Processing chunk 19\n",
      "Chunk 19 processed. Shape: (1542819, 22)\n",
      "Processing chunk 20\n",
      "Chunk 20 processed. Shape: (1513566, 22)\n",
      "Processing chunk 21\n",
      "Chunk 21 processed. Shape: (1522925, 22)\n",
      "Processing chunk 22\n",
      "Chunk 22 processed. Shape: (1536988, 22)\n",
      "Processing chunk 23\n",
      "Chunk 23 processed. Shape: (1361946, 22)\n",
      "Processing chunk 24\n",
      "Chunk 24 processed. Shape: (1493959, 22)\n",
      "Processing chunk 25\n",
      "Chunk 25 processed. Shape: (1522106, 22)\n",
      "Processing chunk 26\n",
      "Chunk 26 processed. Shape: (1450307, 22)\n",
      "Processing chunk 27\n",
      "Chunk 27 processed. Shape: (1522211, 22)\n",
      "Processing chunk 28\n",
      "Chunk 28 processed. Shape: (1527930, 22)\n",
      "Processing chunk 29\n",
      "Chunk 29 processed. Shape: (1556861, 22)\n",
      "Processing chunk 30\n",
      "Chunk 30 processed. Shape: (739242, 22)\n"
     ]
    }
   ],
   "source": [
    "for i, chunk in enumerate(reader):\n",
    "    print(f\"Processing chunk {i + 1}\")\n",
    "\n",
    "    # Melt the wide format into long format\n",
    "    chunk_long = pd.melt(\n",
    "        chunk,\n",
    "        id_vars=['id', 'item_id', 'dept_id', 'store_id', 'cat_id', 'state_id'],\n",
    "        var_name='d',\n",
    "        value_name='sales'\n",
    "    )\n",
    "\n",
    "    # Merge calendar info\n",
    "    chunk_merged = chunk_long.merge(calendar, on=\"d\", how=\"left\")\n",
    "\n",
    "    # Sort before merging prices so ffill works properly\n",
    "    chunk_merged = chunk_merged.sort_values(by=['store_id', 'item_id', 'wm_yr_wk'])\n",
    "\n",
    "    # Merge prices on store_id and item_id only so we're not joining on missing values\n",
    "    chunk_merged = chunk_merged.merge(\n",
    "        prices[['store_id', 'item_id', 'wm_yr_wk', 'sell_price']],\n",
    "        on=['store_id', 'item_id', 'wm_yr_wk'],\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    # Forward fill sell_price within each store-item group\n",
    "    chunk_merged['sell_price'] = (\n",
    "        chunk_merged\n",
    "        .groupby(['store_id', 'item_id'])['sell_price']\n",
    "        .ffill()\n",
    "    )\n",
    "\n",
    "    # Drop rows still missing prices or date\n",
    "    chunk_merged.dropna(subset=['sell_price', 'date'], inplace=True)\n",
    "\n",
    "    print(f\"Chunk {i + 1} processed. Shape: {chunk_merged.shape}\")\n",
    "\n",
    "    chunk_merged = chunk_merged[(chunk_merged['state_id'] == 'CA') & (chunk_merged['cat_id'] == 'FOODS')]\n",
    "    \n",
    "    output_chunks.append(chunk_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2eb9d364-30b9-49e8-8dd3-4887cb6a4547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all chunks\n",
    "full_data = pd.concat(output_chunks, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7486035c-d6ba-4b76-82fe-8dab760b4bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8423403, 22)\n"
     ]
    }
   ],
   "source": [
    "# check to make sure full data is there\n",
    "print(full_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cf50ad2-019d-4247-859e-491e06d95a47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data['month'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16448993-38f2-432b-b663-10f04c562e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011-01-29 2016-04-24\n"
     ]
    }
   ],
   "source": [
    "print(full_data['date'].min(), full_data['date'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9158c09a-fb6a-4de5-b8b2-9265e2ab8eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8423403 entries, 0 to 8423402\n",
      "Data columns (total 22 columns):\n",
      " #   Column        Dtype  \n",
      "---  ------        -----  \n",
      " 0   id            object \n",
      " 1   item_id       object \n",
      " 2   dept_id       object \n",
      " 3   store_id      object \n",
      " 4   cat_id        object \n",
      " 5   state_id      object \n",
      " 6   d             object \n",
      " 7   sales         int64  \n",
      " 8   date          object \n",
      " 9   wm_yr_wk      int64  \n",
      " 10  weekday       object \n",
      " 11  wday          int64  \n",
      " 12  month         int64  \n",
      " 13  year          int64  \n",
      " 14  event_name_1  object \n",
      " 15  event_type_1  object \n",
      " 16  event_name_2  object \n",
      " 17  event_type_2  object \n",
      " 18  snap_CA       int64  \n",
      " 19  snap_TX       int64  \n",
      " 20  snap_WI       int64  \n",
      " 21  sell_price    float64\n",
      "dtypes: float64(1), int64(8), object(13)\n",
      "memory usage: 1.4+ GB\n"
     ]
    }
   ],
   "source": [
    "full_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "567a319b-819f-4b86-893d-aac0de7f8cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved data to:  ../data/processed/ca_food_sales.csv\n"
     ]
    }
   ],
   "source": [
    "# save processed data\n",
    "os.makedirs(DATA_PROCESSED, exist_ok=True)\n",
    "output_path = os.path.join(DATA_PROCESSED, \"ca_food_sales.csv\")\n",
    "full_data.to_csv(output_path, index=False)\n",
    "\n",
    "print(\"saved data to: \", output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9fd739a5-21c2-4de6-8d6c-819e32ce2757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d</th>\n",
       "      <th>sales</th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>...</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "      <th>sell_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FOODS_1_001_CA_1_validation</td>\n",
       "      <td>FOODS_1_001</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>3</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FOODS_1_001_CA_1_validation</td>\n",
       "      <td>FOODS_1_001</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_2</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-30</td>\n",
       "      <td>11101</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FOODS_1_001_CA_1_validation</td>\n",
       "      <td>FOODS_1_001</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_3</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-31</td>\n",
       "      <td>11101</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FOODS_1_001_CA_1_validation</td>\n",
       "      <td>FOODS_1_001</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_4</td>\n",
       "      <td>1</td>\n",
       "      <td>2011-02-01</td>\n",
       "      <td>11101</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FOODS_1_001_CA_1_validation</td>\n",
       "      <td>FOODS_1_001</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_5</td>\n",
       "      <td>4</td>\n",
       "      <td>2011-02-02</td>\n",
       "      <td>11101</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            id      item_id  dept_id store_id cat_id state_id  \\\n",
       "0  FOODS_1_001_CA_1_validation  FOODS_1_001  FOODS_1     CA_1  FOODS       CA   \n",
       "1  FOODS_1_001_CA_1_validation  FOODS_1_001  FOODS_1     CA_1  FOODS       CA   \n",
       "2  FOODS_1_001_CA_1_validation  FOODS_1_001  FOODS_1     CA_1  FOODS       CA   \n",
       "3  FOODS_1_001_CA_1_validation  FOODS_1_001  FOODS_1     CA_1  FOODS       CA   \n",
       "4  FOODS_1_001_CA_1_validation  FOODS_1_001  FOODS_1     CA_1  FOODS       CA   \n",
       "\n",
       "     d  sales        date  wm_yr_wk  ... month  year  event_name_1  \\\n",
       "0  d_1      3  2011-01-29     11101  ...     1  2011           NaN   \n",
       "1  d_2      0  2011-01-30     11101  ...     1  2011           NaN   \n",
       "2  d_3      0  2011-01-31     11101  ...     1  2011           NaN   \n",
       "3  d_4      1  2011-02-01     11101  ...     2  2011           NaN   \n",
       "4  d_5      4  2011-02-02     11101  ...     2  2011           NaN   \n",
       "\n",
       "   event_type_1 event_name_2 event_type_2 snap_CA snap_TX  snap_WI  sell_price  \n",
       "0           NaN          NaN          NaN       0       0        0         2.0  \n",
       "1           NaN          NaN          NaN       0       0        0         2.0  \n",
       "2           NaN          NaN          NaN       0       0        0         2.0  \n",
       "3           NaN          NaN          NaN       1       1        0         2.0  \n",
       "4           NaN          NaN          NaN       1       0        1         2.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b73551-a5aa-4b2c-ac80-df36a8ad6789",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
